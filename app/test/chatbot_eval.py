# /Users/minsun/Desktop/8-pumati-ai/app/test/chatbot_eval.py

import os
import csv
import time
from dotenv import load_dotenv
import google.generativeai as genai

from app.model_inference.rag_chat_runner import run_rag

# ğŸ” í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()
genai.configure(api_key=os.getenv("GEMINI_API_KEY"))

# âœ… Gemini í‰ê°€ í•¨ìˆ˜
def evaluate_with_gemini(question, answer, context, eval_type="accuracy"):
    if eval_type == "accuracy":
        prompt = f"""
ë‹¤ìŒì€ ì‚¬ìš©ì ì§ˆë¬¸, ì±—ë´‡ ì‘ë‹µ, ê·¸ë¦¬ê³  ë¬¸ì„œ ë‚´ìš©ì…ë‹ˆë‹¤.
ì±—ë´‡ ì‘ë‹µì´ ë¬¸ì„œì— ê¸°ë°˜í•´ ì‚¬ì‹¤ì— ë§ê²Œ ì‘ì„±ë˜ì—ˆëŠ”ì§€ í‰ê°€í•˜ì„¸ìš”.
ë¬¸ì„œì— ì—†ëŠ” ë‚´ìš©ì„ í¬í•¨í•˜ê±°ë‚˜ ì˜ëª»ëœ ì •ë³´ë¥¼ ë‹´ê³  ìˆë‹¤ë©´ "False",
ë¬¸ì„œ ë‚´ìš©ê³¼ ì¼ì¹˜í•˜ê³  í—ˆìœ„ ì •ë³´ê°€ ì—†ë‹¤ë©´ "True"ë§Œ ì¶œë ¥í•˜ì„¸ìš”.

ì§ˆë¬¸:
{question}

ì±—ë´‡ ì‘ë‹µ:
{answer}

ë¬¸ì„œ ë‚´ìš©:
{context}

ì •ë‹µ:
"""
    elif eval_type == "conciseness":
        prompt = f"""
ë‹¤ìŒì€ ì‚¬ìš©ì ì§ˆë¬¸ê³¼ ì±—ë´‡ ì‘ë‹µì…ë‹ˆë‹¤.
ì±—ë´‡ ì‘ë‹µì´ ì–¼ë§ˆë‚˜ ê°„ê²°í•˜ê²Œ í•µì‹¬ë§Œ ìš”ì•½í–ˆëŠ”ì§€ë¥¼ 1~5ì ìœ¼ë¡œ í‰ê°€í•˜ì„¸ìš”.

- ë§¤ìš° ê°„ê²°í•˜ë©´ 5ì 
- ì¥í™©í•˜ê±°ë‚˜ ë°˜ë³µë˜ëŠ” ë§ì´ ë§ìœ¼ë©´ 1ì ì…ë‹ˆë‹¤.

ì§ˆë¬¸:
{question}

ì±—ë´‡ ì‘ë‹µ:
{answer}

ì •ë‹µ (1~5 ì¤‘ í•˜ë‚˜ì˜ ìˆ«ìë§Œ ì‘ì„±):
"""
    else:
        raise ValueError("ì§€ì›í•˜ì§€ ì•ŠëŠ” í‰ê°€ ìœ í˜•ì…ë‹ˆë‹¤: accuracy ë˜ëŠ” conciseness ì¤‘ ì„ íƒí•˜ì„¸ìš”.")

    model = genai.GenerativeModel("gemini-pro")
    response = model.generate_content(prompt.strip())
    result = response.text.strip()
    time.sleep(1)  # âœ… ê³¼ê¸ˆ ë°©ì§€ë¥¼ ìœ„í•œ sleep

    return result

# âœ… ì „ì²´ í‰ê°€ ì‹¤í–‰ í•¨ìˆ˜
def evaluate_questions_from_csv(csv_path, project_id=1, output_path="rag_eval_result.csv"):
    results = []
    with open(csv_path, newline='', encoding='utf-8') as csvfile:
        reader = csv.DictReader(csvfile)
        for row in reader:
            question = row["question"]
            context = row["ground_truth"]

            print(f"\nğŸ§ª ì§ˆë¬¸: {question}")

            # ğŸ” ì±—ë´‡ ì‘ë‹µ ìƒì„±
            answer = run_rag(question, project_id=project_id)
            print(f"ğŸ¤– ì‘ë‹µ: {answer}")

            # ğŸ” í‰ê°€ ìˆ˜í–‰
            accuracy_eval = evaluate_with_gemini(question, answer, context, "accuracy")
            conciseness_eval = evaluate_with_gemini(question, answer, context, "conciseness")

            print(f"âœ… ì •í™•ì„± í‰ê°€: {accuracy_eval} / ê°„ê²°ì„± í‰ê°€: {conciseness_eval}")

            results.append({
                "question": question,
                "chatbot_answer": answer,
                "ground_truth": context,
                "accuracy_eval": accuracy_eval,
                "conciseness_eval": conciseness_eval
            })

    with open(output_path, "w", newline='', encoding='utf-8') as f:
        writer = csv.DictWriter(f, fieldnames=results[0].keys())
        writer.writeheader()
        writer.writerows(results)

    print(f"\nğŸ‰ í‰ê°€ ì™„ë£Œ â†’ ê²°ê³¼ ì €ì¥: {output_path}")
    return output_path

# âœ… ì‹¤í–‰ ì—”íŠ¸ë¦¬í¬ì¸íŠ¸
if __name__ == "__main__":
    evaluate_questions_from_csv("questions.csv", project_id=1)
