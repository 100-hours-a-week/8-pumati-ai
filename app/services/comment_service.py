import json, re, logging
from summa.summarizer import summarize
from context_construction.prompts.comment_prompt import GemmaPrompt
from sentence_transformers import util
from model_inference.loaders.comment_loader import comment_creator
from fast_api.schemas.comment_schemas import CommentRequest
from transformers import TextStreamer
import torch

logger = logging.getLogger(__name__)

FALLBACK_COMMENT = "ì¢‹ì•„ìš”! ì¶”ì²œí•©ë‹ˆë‹¤! ğŸ™Œ"

MAX_NEW_TOKENS = 100 #80
MAX_RETRY = 8

class GenerateComment:
    def __init__(self):
        self.pipe = comment_creator.pipe
        self.model = comment_creator.model
        self.tokenizer = comment_creator.tokenizer
        self.embed_model = comment_creator.embed_model

    def validate_generated_comment(self, generated_comment_dict: dict) -> bool:
        comment = generated_comment_dict.get("comment", "")
        if not isinstance(comment, str) or not comment.strip():
            return False
        if len(comment.split()) <= 2:
            return False
        for word in ['ì¶”ê°€', 'ì½”ë”©', 'ì½”ë“œ', 'ë§ì¶¤', 'ì¹´í…Œê·¸ë¨', 'ì¹´í…Œë¸Œ', 'ì•±', 'ì–´í”Œë¦¬ì¼€ì´ì…˜', 'ì„¤ì¹˜', 'ì•Œë¦¼']:
            if word in comment:
                return False
        return True

    def is_semantically_relevant(self, comment: str, context: str, threshold: float = 0.60) -> bool:
        logger.info(f"6-5-7) ìœ ì‚¬ë„ ì¸¡ì •ì„ ì‹œì‘í•©ë‹ˆë‹¤. comment: '{comment}'")
        comment_emb = self.embed_model.encode(comment, convert_to_tensor=True, show_progress_bar=False)
        context_emb = self.embed_model.encode(context, convert_to_tensor=True, show_progress_bar=False)
        similarity = util.cos_sim(comment_emb, context_emb).item()
        logger.info(f"6-5-8) ì˜ë¯¸ ìœ ì‚¬ë„: {similarity:.2f}, threshold: {threshold}")
        return similarity >= threshold
    
    # def detail_summary(self, detail_Description: str) -> str:
    #     detailed_length = len(detail_Description)
    #     if detailed_length < 180:
    #         ratio = 1

    #     elif detailed_length < 500:
    #         ratio = 0.7

    #     else:
    #         ratio = 0.6
        
    #     summary = summarize(detail_Description, ratio=ratio) or detail_Description
    #     summary = summarize(summary, ratio=ratio) or summary

    #     return summary

    def generate_comment(self, request_data: CommentRequest) -> str:
        logger.info(f"5-1) í”„ë¡¬í”„íŠ¸ ìƒì„±ì„ ìœ„í•œ ë°ì´í„° ì „ì²˜ë¦¬ë¥¼ ì§„í–‰í•©ë‹ˆë‹¤.")
        prompt_builder = GemmaPrompt(request_data)

        logger.info(f"6-1) ìœ ì‚¬ë„ê¸°ë°˜ ê²€ì—´ ë¡œì§ì„ ìœ„í•´ contextë¥¼ ìƒì„±í•©ë‹ˆë‹¤.")
        context_text = " ".join(["ë‹¤ìŒì€ í”„ë¡œì íŠ¸ì˜ ì „ë°˜ì ì¸ ì •ë³´ì´ë‹¤.",
            "ì„œë¹„ìŠ¤ ì´ë¦„ì€", prompt_builder.title,
            "ì´ë‹¤. í”„ë¡œì íŠ¸ ìŠ¬ë¡œê±´ì€", prompt_builder.introduction,
            "ì´ë‹¤.", prompt_builder.detailedDescription,
            "í”„ë¡œì íŠ¸ì˜ ì •ë³´ì— ì•Œë§ì€ ëŒ“ê¸€ì„ ìƒì„±í•´ì£¼ì„¸ìš”."
        ])

        logger.info(f"6-2) ì…ë ¥ ë¬¸ìì˜ ê¸¸ì´ê°€ ê¸´ ê²½ìš°, ê° ê²½ìš°ì— ë§ë„ë¡ ìš”ì•½í•©ë‹ˆë‹¤.")
        prompt_builder.detailedDescription = prompt_builder.detail_summary(prompt_builder.detailedDescription)
        logger.info(f"6-3) ì£¼ì–´ì§„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ í”„ë¡¬í”„íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.")
        gemma_prompt = prompt_builder.generate_prompt()

        # if len(prompt_builder.detailedDescription) < 180:
        #     pass

        # elif len(prompt_builder.detailedDescription) < 500:
        #     prompt_builder.detailedDescription = self.detail_summary(prompt_builder.detailedDescription, 0.7)
        # else:
        #     prompt_builder.detailedDescription = self.detail_summary(prompt_builder.detailedDescription, 0.6)
        #     #print(summary)

        logger.info(f"6-4) í”„ë¡¬í”„íŠ¸ë¥¼ í† í°IDë¡œ ë³€í™˜í•©ë‹ˆë‹¤.")
        #inputs = self.tokenizer(gemma_prompt, return_tensors="pt").to(self.model.device)

        for attempt in range(1, MAX_RETRY + 1):
            logger.info(f"ëŒ“ê¸€ ìƒì„± ì‹œë„ {attempt}íšŒ")
            logger.info(f"6-5-1) ëŒ“ê¸€ì„ ìƒì„±í•©ë‹ˆë‹¤.")
            # with torch.inference_mode():
            #     outputs = self.model.generate(
            #         **inputs,
            #         max_new_tokens=MAX_NEW_TOKENS,
            #         temperature= 0.6,#0.7,
            #         top_p=0.9,
            #         repetition_penalty=1.1,
            #         do_sample=True
            #     )

            outputs = comment_creator.pipe(
                gemma_prompt,
                max_new_tokens=100,
                do_sample=True,
                temperature=0.6,
                top_p=0.9,
                repetition_penalty=1.1
            )

            logger.info(f"6-5-2) ìƒì„±ëœ outputì—ì„œ í”„ë¡¬í”„íŠ¸ ë¶€ë¶„ì„ ì œê±°í•©ë‹ˆë‹¤.")
            # output_text = self.tokenizer.decode(outputs[0], skip_special_tokens=True).strip()
            # logger.info(f"6-5-3) ìƒì„±ëœ ëŒ“ê¸€ì—ì„œ í”„ë¡¬í”„íŠ¸ ë¶€ë¶„ì„ ì œê±°í•©ë‹ˆë‹¤.")
            # output_text = output_text[len(gemma_prompt):].strip()
            output_text = outputs[0]["generated_text"][len(gemma_prompt):].strip()

            try:
                logger.info(f"6-5-3) ìƒì„±ëœ ëŒ“ê¸€ ê²€ì—´ì„ ì‹œì‘í•©ë‹ˆë‹¤.")
                find_comment = re.findall(r'{.*?}', output_text, re.DOTALL)
                generated_comment_dict = json.loads(find_comment[0].strip())

                if self.validate_generated_comment(generated_comment_dict):
                    logger.info(f"6-5-4) JSON í˜•íƒœë¡œ ì¶œë ¥ ì„±ê³µ.")
                    comment = generated_comment_dict.get("comment", "").strip()

                    logger.info(f"6-5-5) JSONì—ì„œ '{comment}'ë¥¼ ì¶œë ¥í•˜ì˜€ìŠµë‹ˆë‹¤.")
                    if any(word in comment for word in ["ë””ìì¸", "UI", "UX", "ì¢‹ì•„ìš”", "ì¸í„°í˜ì´ìŠ¤"]): #prompt_builder.tags +
                        logger.info(f"6-5-6) tags ê¸°ë°˜ì˜ ëŒ“ê¸€ìƒì„±ì— ì„±ê³µí•˜ì˜€ìŠµë‹ˆë‹¤.")
                        #logger.info(f"ëŒ“ê¸€ ìƒì„± ì„±ê³µ: {comment}")
                        return comment
                    if self.is_semantically_relevant(comment, context_text):
                        logger.info(f"6-5-9) ìƒì„¸ë‚´ìš©ê³¼ ìœ ì‚¬ë„ ì¸¡ì •í•˜ì—¬, ëŒ“ê¸€ìƒì„±ì— ì„±ê³µí•˜ì˜€ìŠµë‹ˆë‹¤.")
                        logger.info(f"ëŒ“ê¸€ ìƒì„± ì„±ê³µ: {comment}")
                        return comment
                    raise ValueError("ì˜ë¯¸ ê²€ì—´ ë¶ˆí†µê³¼")
                raise ValueError("JSON í˜•íƒœ ì•„ë‹˜.")
            except Exception as e:
                logger.warning(f"ëŒ“ê¸€ ìƒì„± ì‹¤íŒ¨ (ì‹œë„ {attempt}íšŒ): {e}")

        logger.warning("ìµœëŒ€ ì¬ì‹œë„ ë„ë‹¬ â†’ fallback ì‚¬ìš©")
        return FALLBACK_COMMENT