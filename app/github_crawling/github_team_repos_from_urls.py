# app/github_crawling/github_team_repos_from_urls.py

import requests
import os
import re
from dotenv import load_dotenv

load_dotenv()
GITHUB_TOKEN = os.getenv("GITHUB_TOKEN")
ORG_NAME = os.getenv("ORG_NAME")
TEAM_LIST_API_URL = os.getenv("TEAM_LIST_API_URL")
USE_BACKEND_API_RAW = os.getenv("USE_BACKEND_API")
USE_BACKEND_API = USE_BACKEND_API_RAW and USE_BACKEND_API_RAW.lower() == "true"

HEADERS = {
    "Authorization": f"Bearer {GITHUB_TOKEN}",
    "Accept": "application/vnd.github+json"
}

# USE_BACKEND_API=False # í…ŒìŠ¤íŠ¸ìš©

def fetch_team_meta():
    print(f"ğŸ› USE_BACKEND_API ê°’: {USE_BACKEND_API}")
    if USE_BACKEND_API:
        print("ğŸŒ ë°±ì—”ë“œ APIë¥¼ í†µí•´ íŒ€ ë©”íƒ€ë°ì´í„°ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.")
        print(f"ğŸ”— ìš”ì²­ URL: {TEAM_LIST_API_URL}")
        try:
            res = requests.get(TEAM_LIST_API_URL, timeout=10)
            print(f"ğŸ“¥ ì‘ë‹µ ìƒíƒœ ì½”ë“œ: {res.status_code}")
            res.raise_for_status()

            result = res.json()
            print(f"ğŸ“¦ API ì‘ë‹µ ë‚´ìš©: {result}")

            # 'data' í•„ë“œ ìœ íš¨ì„± ê²€ì‚¬ ì¶”ê°€
            if "data" not in result:
                print(f"âŒ API ì‘ë‹µì— 'data' í•„ë“œê°€ ì—†ìŠµë‹ˆë‹¤. result: {result}")
                return [], {}

            team_urls = []
            team_meta = {}
            for item in result["data"]:
                url = item["githubUrl"]
                project_id = item["projectId"]
                slug = url.split("/")[-1]
                team_urls.append(url)
                team_meta[slug] = project_id
            return team_urls, team_meta
        except Exception as e:
            print(f"âŒ [API ì‹¤íŒ¨] íŒ€ ëª©ë¡ì„ ë¶ˆëŸ¬ì˜¤ëŠ” ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤, api/projects/github-urlsì‹¤íŒ¨, ë°±ì—”ë“œ ì„œë²„ ì¼œì¡ŒëŠ”ì§€ í™•ì¸ í•„ìš”: {e}")
            return [], {}
    else:
        # ìˆ˜ë™ fallback í…ŒìŠ¤íŠ¸ìš©
        team_urls = [
            "https://github.com/orgs/100-hours-a-week/teams/8",
            # "https://github.com/orgs/100-hours-a-week/teams/1",
            # "https://github.com/orgs/100-hours-a-week/teams/7-1",
            # "https://github.com/orgs/100-hours-a-week/teams/20",
            # "https://github.com/orgs/100-hours-a-week/teams/13-cafeboo",

        ]
        team_meta = {
            "8": 6,
            # "1": 9
        }
        return team_urls, team_meta

def extract_team_slugs_from_urls(urls):
    slugs = []
    for url in urls:
        match = re.search(r'/teams/([^/]+)$', url)
        if match:
            slugs.append(match.group(1))
    return slugs

def get_team_repos(org, team_slug):
    url = f"https://api.github.com/orgs/{org}/teams/{team_slug}/repos"
    try:
        res = requests.get(url, headers=HEADERS, timeout=15)  # timeout ì¶”ê°€
        if res.status_code == 404:
            print(f"âŒ [Team: {team_slug}] Not found or no access.")
            return []
        res.raise_for_status()
        return res.json()
    except requests.exceptions.Timeout:
        print(f"â±ï¸ [Team: {team_slug}] ìš”ì²­ ì‹œê°„ì´ ì´ˆê³¼ë˜ì—ˆìŠµë‹ˆë‹¤.")
        return []
    except requests.exceptions.RequestException as e:
        print(f"âš ï¸ [Team: {team_slug}] ìš”ì²­ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return []


def get_all_repos_from_team_urls():
    TEAM_URLS, TEAM_META = fetch_team_meta()
    team_slugs = extract_team_slugs_from_urls(TEAM_URLS)
    all_repos = []
    for slug in team_slugs:
        try:
            repos = get_team_repos(ORG_NAME, slug)
            team_id = TEAM_META.get(slug, 0)
            for repo in repos:
                all_repos.append((repo["full_name"], team_id, slug)) 
        except Exception as e:
            print(f"âš ï¸ íŒ€ {slug} ì—ëŸ¬: {e}")
    print("\nâœ… ì „ì²´ REPOS ë¦¬ìŠ¤íŠ¸")
    print("REPOS = [")
    for r in all_repos:
        print(f'    "{r[0]}",')
    print("]")
    return all_repos

if __name__ == "__main__":
    get_all_repos_from_team_urls()
