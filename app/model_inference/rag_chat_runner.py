# app/model_inference/rag_chat_runner.py

from langchain_chroma import Chroma
from langchain_huggingface import HuggingFaceEmbeddings
from langchain.prompts import PromptTemplate
from langchain.chains.combine_documents import create_stuff_documents_chain
from langchain.chains.retrieval import create_retrieval_chain
from langsmith import traceable

from app.model_inference.loaders.hyperclova_langchain_llm import HyperClovaLangChainLLM
from app.context_construction.question_router import classify_question_type
from app.context_construction.prompts import (
    chat_prompt_summary,
    chat_prompt_timeline,
    chat_prompt_owner,
)

from dotenv import load_dotenv
load_dotenv()

# ğŸ”¹ ì§ˆë¬¸ ìœ í˜•ë³„ í”„ë¡¬í”„íŠ¸ ë§¤í•‘
prompt_map = {
    "summary": chat_prompt_summary,
    "timeline": chat_prompt_timeline,
    "owner": chat_prompt_owner,
}

# ğŸ”¹ ì„ë² ë”© ëª¨ë¸ ë° ë²¡í„°ìŠ¤í† ì–´ ë¡œë”©
embedding_model = HuggingFaceEmbeddings(model_name="intfloat/multilingual-e5-base")
vectorstore = Chroma(
    collection_name="github_docs",
    persist_directory="./chroma_db_e5_base",
    embedding_function=embedding_model,
)

# ğŸ”¹ LLM (HyperCLOVA)
llm = HyperClovaLangChainLLM()

# ğŸ”¹ ì‹¤í–‰ í•¨ìˆ˜
@traceable
def run_rag(question: str, project_id: int) -> str:
    # 1. ë¬¸ì„œ ê²€ìƒ‰ê¸° êµ¬ì„±
    retriever = vectorstore.as_retriever(search_kwargs={"k": 10, "filter": {"project_id": project_id}})

    # 2. í”„ë¡¬í”„íŠ¸ ì„ íƒ ë° ìƒì„±
    q_type = classify_question_type(question)
    prompt_builder = prompt_map[q_type].build_prompt

    # 3. LangChain Template (ë¬¸ì„œ contextëŠ” LangChainì´ ìë™ ì „ë‹¬)
    dynamic_prompt = PromptTemplate(
        input_variables=["context", "input"],
        template=prompt_builder(context="{context}", question="{input}")
    )

    # 4. ìµœì‹  ë°©ì‹ìœ¼ë¡œ ì²´ì¸ êµ¬ì„±
    combine_docs_chain = create_stuff_documents_chain(llm=llm, prompt=dynamic_prompt)
    rag_chain = create_retrieval_chain(retriever=retriever, combine_docs_chain=combine_docs_chain)

    # 5. ì‹¤í–‰
    return rag_chain.invoke({"input": question})

