import os
import re
import json
import logging
from dotenv import load_dotenv
from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline
from sentence_transformers import SentenceTransformer, util
import torch
from huggingface_hub import login
from context_construction.query_rewriter import ClovaxPrompt
from fast_api.schemas.comment_schemas import CommentRequest
from summa.summarizer import summarize

# ----------------------------
# ë¡œê¹… ì„¤ì •
# ----------------------------

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# ----------------------------
# ìƒìˆ˜ ì •ì˜
# ----------------------------

#gemmaë¡œ ëª¨ë¸ ë³€ê²½
MODEL_NAME = "google/gemma-3-1b-it"#""naver-hyperclovax/HyperCLOVAX-SEED-Text-Instruct-1.5B" #"google/gemma-3-1b-it" 
FALLBACK_COMMENT = '{\n"comment": "ê°œë°œì ì…ì¥ì—ì„œ ì •ë§ í•„ìš”í•œ ì„œë¹„ìŠ¤ ê°™ì•„ìš”, ëŒ€ë‹¨í•©ë‹ˆë‹¤! ğŸ™Œ" \n}'
EMBEDDING_MODEL_NAME = "intfloat/multilingual-e5-small"#"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2"
CPU_DEVICE = torch.device("cpu")
MAX_NEW_TOKENS = 80
MAX_NEW_TOKENS_SUMMARY = 50
TEMPERATURE = 0.85
TOP_P = 0.8
REPETITION_PENALTY = 1.2
MAX_RETRY = 50



# ----------------------------
# ClovaxModel í´ë˜ìŠ¤
# ----------------------------

class ClovaxModel:
    """
    Clovax ëª¨ë¸ì„ ì‚¬ìš©í•´ ëŒ“ê¸€ ìƒì„±ì„ ë‹´ë‹¹í•˜ëŠ” í´ë˜ìŠ¤
    """
    _is_authenticated = False
    def __init__(self):
        self._authenticate_huggingface()
        self.model_name = MODEL_NAME
        self.device = CPU_DEVICE
        self.tokenizer = None
        self.model = None
        self.pipe = None
        logger.info(f"Device ì„¤ì •: DeviceëŠ” ì˜ë„ì ìœ¼ë¡œ CPUë¡œ ê³ ì •ë©ë‹ˆë‹¤.")
        self.embed_model = None
        
    
    def _authenticate_huggingface(self) -> None:
        """
        .env íŒŒì¼ì—ì„œ HF_AUTH_TOKENì„ ë¡œë“œí•˜ê³  ë¡œê·¸ì¸í•œë‹¤.
        ì¸ì¦ ìµœì í™”ë¥¼ ìœ„í•´ _is_authenticatedê°€ Falseì¼ ê²½ìš°ë§Œ ë¡œê·¸ì¸í•œë‹¤.
        """
        if ClovaxModel._is_authenticated:
            logger.info("Hugging Face ì¸ì¦ ì´ë¯¸ ì™„ë£Œë¨.")
            return  # ì´ë¯¸ ì¸ì¦ë¨ â†’ ê·¸ëƒ¥ ë„˜ì–´ê°

        load_dotenv()
        token = os.getenv("HF_AUTH_TOKEN")
        if not token:
            raise EnvironmentError("HF_AUTH_TOKEN is not set in .env file.")
        login(token=token)

        ClovaxModel._is_authenticated = True  # ì¸ì¦ ì™„ë£Œ ì²˜ë¦¬
        logger.info("Hugging Face ì¸ì¦ ì™„ë£Œ.")


    def load_clovax(self) -> None:
        """
        ëª¨ë¸ê³¼ í† í¬ë‚˜ì´ì €ë¥¼ ë¡œë“œí•˜ì—¬ íŒŒì´í”„ë¼ì¸ì„ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.
        ì´ë¯¸ ì´ˆê¸°í™”ëœ ê²½ìš° ì•„ë¬´ ì‘ì—…ë„ í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
        """
        if self.pipe is None: 
            self.tokenizer = AutoTokenizer.from_pretrained(self.model_name)
            self.model = AutoModelForCausalLM.from_pretrained(self.model_name).to(self.device)
            self.pipe = pipeline(
                "text-generation", 
                model=self.model, 
                tokenizer=self.tokenizer, 
                device=-1, 
                temperature=TEMPERATURE, 
                top_p=TOP_P, 
                do_sample=True,
                repetition_penalty=REPETITION_PENALTY
            )
            self.embed_model = SentenceTransformer(EMBEDDING_MODEL_NAME, device = self.device)
            logger.info("Clovax ëª¨ë¸ ë¡œë“œ ì™„ë£Œ.")
            logger.info("ì„ë² ë”© ê¸°ë°˜ ê²€ì—´ ëª¨ë¸ ë¡œë“œ ì™„ë£Œ.")


    # ëŒ“ê¸€ ìƒì„±
    def validate_generated_comment(self, generated_comment_dict: dict) -> bool:
        """
        ìƒì„±ëœ ëŒ“ê¸€ JSONì´ ìœ íš¨í•œì§€ ê²€ì‚¬.
        í•„ìˆ˜ í•„ë“œ(comment)ê°€ ì—†ê±°ë‚˜ ê°’ì´ ë¹„ì–´ìˆìœ¼ë©´ False
        """
        if "comment" not in generated_comment_dict:
            return False

        comment = generated_comment_dict["comment"]

        if not isinstance(comment, str) or not comment.strip():
            return False
        
        for word in ['ì¶”ê°€', 'í˜ì‹ ì ', 'ì½”ë”©', 'ì½”ë“œ', 'ë§ì¶¤']:
            if word in comment:
                return False
        
        if len(comment.split()) <= 2:
            return False

        return True


    def generate_comment(self, request_data: CommentRequest) -> dict:
        prompt_builder = ClovaxPrompt(request_data)
        prompt: str = prompt_builder.generate_prompt()


        summary = summarize(prompt_builder.detailedDescription, ratio=0.7)
        summary = summarize(summary, ratio=0.7)
        request_data.projectSummary.detailedDescription = summary
        print(summary)

        # ğŸ’¡ ê²€ì—´ ê¸°ì¤€ í…ìŠ¤íŠ¸ ìƒì„± (ìš”ì•½, ì„¤ëª…, íƒœê·¸ ë“± ì¡°í•©)
        context_text = " ".join(["ì„œë¹„ìŠ¤ ì´ë¦„ì€",
            prompt_builder.title, "ì´ë‹¤. í”„ë¡œì íŠ¸ ìŠ¬ë¡œê±´ì€",
            prompt_builder.introduction, "ì´ë‹¤.",
            prompt_builder.detailedDescription #, "ì´ í”„ë¡œì íŠ¸ì˜ í•µì‹¬ì ì¸ íŠ¹ì§•ì€"
            #",".join(ClovaxPrompt.projectSummary.tags), "ì´ë‹¤"
        ])


        for attempt in range(1, MAX_RETRY + 1):
            logger.info(f"ëŒ“ê¸€ ìƒì„± ì‹œë„ {attempt}íšŒ")
            outputs = self.pipe(prompt, max_new_tokens=MAX_NEW_TOKENS)[0]["generated_text"]
            output_text = outputs[len(prompt):].strip()

            try:
                find_comment = re.findall(r'{.*?}', output_text, re.DOTALL)
                generated_comment_str = find_comment[0].strip()
                generated_comment_dict = json.loads(generated_comment_str)
                print(generated_comment_dict)

                # ìœ íš¨ì„± ê²€ì‚¬ ì¶”ê°€
                if self.validate_generated_comment(generated_comment_dict):
                    #logger.info("JSON íŒŒì‹± + ìœ íš¨ì„± ê²€ì‚¬ ì„±ê³µ.")
                    generated_comment = generated_comment_dict.get("comment", "").strip()

                    if self.is_semantically_relevant(generated_comment, context_text):
                        logger.info("JSON íŒŒì‹± + ì˜ë¯¸ í•„í„°ë§ í†µê³¼.")
                        return generated_comment

                    else:
                        logger.info("ì˜ë¯¸ ê²€ì—´ì— ì˜í•´ ëŒ“ê¸€ ì¬ ìƒì„± í•„ìš”.")
                else:
                    raise ValueError("ìƒì„±ëœ JSONì— commentê°€ ì—†ê±°ë‚˜ ë¹„ì–´ ìˆìŒ. í˜•ì‹ì— ë²—ì–´ë‚¨.")

            except (IndexError, json.JSONDecodeError, ValueError) as e:
                logger.warning(f"ëŒ“ê¸€ ìƒì„± ì‹¤íŒ¨ (ì‹œë„ {attempt}íšŒ): {e}")

                if attempt < MAX_RETRY:
                    continue
                else:
                    logger.warning("ìµœëŒ€ ì¬ì‹œë„ ë„ë‹¬ â†’ fallback ì‚¬ìš©.")
                    return json.loads(FALLBACK_COMMENT)


    def is_semantically_relevant(self, comments: str, context: str, threshold: float = 0.86) -> bool:
        """
        ê²€ì—´í•¨ìˆ˜ ìƒì„±. ìƒì„±ëœ ëŒ“ê¸€ì´ í”„ë¡œì íŠ¸ ì •ë³´ì™€ ì˜ë¯¸ì ìœ¼ë¡œ ê´€ë ¨ ìˆëŠ”ì§€ ìœ ì‚¬ë„ë¡œ íŒë‹¨
        """
        comment_emb = self.embed_model.encode("query: " + comments, convert_to_tensor=True, show_progress_bar=False)
        context_emb = self.embed_model.encode("passage: " + context, convert_to_tensor=True, show_progress_bar=False)
        similarity = util.cos_sim(comment_emb, context_emb).item()

        logger.info(f"ì˜ë¯¸ ìœ ì‚¬ë„: {similarity:.4f}")
        return similarity >= threshold


    
# ì‹±ê¸€í„´ ì¸ìŠ¤í„´ìŠ¤ ìƒì„± (ì„œë²„ ì‹œì‘ ì‹œ 1íšŒë§Œ ì‹¤í–‰)
clovax_model_instance = ClovaxModel()
clovax_model_instance.load_clovax()

# ----------------------------
# í…ŒìŠ¤íŠ¸ ì½”ë“œ
# ---------------------------- 

if __name__ == "__main__":
    import time
    from fast_api.schemas.comment_schemas import ProjectSummary

    dummy_data = CommentRequest(
        commentType="ì¹­ì°¬",
        projectSummary=ProjectSummary(
            title= "ëª¨ì•„",
            introduction= "JUST SWIPE! ì¹´í…Œë¶€ ì‚¬ëŒë“¤ê³¼ ìµëª…ìœ¼ë¡œ ì¬ë°Œê³  ë¹ ë¥´ê²Œ ì†Œí†µí•´ìš”",
            detailedDescription= "### ëª¨ì•„(Moa) - ëª¨ë‘ì˜ ì•„ì  ë‹¤\n\n- ìŠ¤ì™€ì´í”„ë¡œ íˆ¬í‘œ, AIê°€ ì§€ì¼œì£¼ëŠ” íˆ¬í‘œ ê³µê°„\n- ëˆ„êµ¬ë‚˜ ì‰½ê²Œ ë§Œë“¤ê³  íˆ¬í‘œí•˜ëŠ”, AI ë¡œ ë” ì¾Œì í•œ íˆ¬í‘œ ê³µê°„\n\n### ì„œë¹„ìŠ¤ ì†Œê°œ\n\nâ€œì—ì–´ì»¨ì„ ì¼œì!â€ë¶€í„°\n\nâ€œì´ë²ˆ ì£¼ ì•¼ê·¼ í•˜ì‹œëŠ” ë¶„?â€ê¹Œì§€\n\nëª¨ì•„ëŠ” ì¼ìƒ ì† ëª¨ë“  ì„ íƒì„ ê°„í¸í•œ ìŠ¤ì™€ì´í”„ í•œë²ˆìœ¼ë¡œ ëª¨ì•„ì£¼ëŠ” íˆ¬í‘œ í”Œë«í¼ì…ë‹ˆë‹¤.\n\n- ìŠ¤ì™€ì´í”„ë¡œ ë¹ ë¥¸ íˆ¬í‘œ ì°¸ì—¬\n- AI ê°€ ë¹„ì†ì–´, ìŠ¤íŒ¸ ìë™ ê²€ì—´\n- ê·¸ë£¹ ë‹¨ìœ„ íˆ¬í‘œ ìƒì„±ê³¼ ì°¸ì—¬\n- ê²°ê³¼ëŠ” ê·¸ë£¹ë³„, ì°¸ì—¬, ìƒì„±ë³„ë¡œ í•œëˆˆì—\n\në³µì¡í•œ UI, ê±°ì¹œ í‘œí˜„, ê³µê°œëœ ê²Œì‹œíŒì€ ì´ì œ ê·¸ë§Œ,\n\nëª¨ì•„ì—ì„œëŠ” ëª¨ë“  íˆ¬í‘œê°€ ë¶€ë“œëŸ½ê³  ì•ˆì „í•˜ê²Œ íë¦…ë‹ˆë‹¤.\n\n---\n\n### ëª¨ì•„ëŠ” ì´ëŸ° ë¶„ê»˜!\n\n- ëª¨ì„ì´ë‚˜ ë™ì•„ë¦¬ì—ì„œ ë¹ ë¥´ê²Œ ì˜ê²¬ì„ ëª¨ì„ ë•Œ\n- ì»¤ë®¤ë‹ˆí‹°ì—ì„œ ê±´ê°•í•œ ì˜ê²¬ ìˆ˜ë ´ ë¬¸í™”ë¥¼ ë§Œë“¤ê³  ì‹¶ì„ ë•Œ\n- íŒ€ í”„ë¡œì íŠ¸ ì¤‘ í•©ë¦¬ì  ì˜ì‚¬ ê²°ì •ì„ ë‚´ë¦¬ê³  ì‹¶ì„ ë•Œ\n\nëª¨ë“  ì•„ì  ë‹¤ë¥¼ ìœ„í•œ,\n\nëª¨ë‘ì˜ ì„ íƒì„ ìœ„í•œ ê³µê°„, ëª¨ì•„",
            deploymentUrl= "https://moagenda.com/",
            githubUrl= "https://github.com/100-hours-a-week/4-bull4zo-wiki/wiki",
            tags= ["ì¹´í…Œë¶€","íˆ¬í‘œ","ìŠ¤ì™€ì´í”„","ì†Œí†µ","ì»¤ë®¤ë‹ˆí‹°"],
            teamId= 6
        )
    )
    

    start = time.time()
    logger.info("í…ŒìŠ¤íŠ¸ ì‹œì‘.")
    # clovax_model_instance.summary_detailed(dummy_data)
    correct = []
    for _ in range(4):
        comment = clovax_model_instance.generate_comment(dummy_data)
        correct.append(comment)
        logger.info("ìƒì„±ëœ ëŒ“ê¸€: %s", comment)
        logger.info("ì‹¤í–‰ ì‹œê°„: %.2fì´ˆ", time.time() - start)

    print(correct)