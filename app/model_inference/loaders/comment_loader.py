import os
import re
import json
import logging
from dotenv import load_dotenv
from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline
from sentence_transformers import SentenceTransformer, util
import torch
from huggingface_hub import login
from app.context_construction.query_rewriter import ClovaxPrompt
from app.fast_api.schemas.comment_schemas import CommentRequest

# ----------------------------
# ë¡œê¹… ì„¤ì •
# ----------------------------

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# ----------------------------
# ìƒìˆ˜ ì •ì˜
# ----------------------------

MODEL_NAME = "naver-hyperclovax/HyperCLOVAX-SEED-Text-Instruct-1.5B" #"google/gemma-3-1b-it"
FALLBACK_COMMENT = '{\n"comment": "ê°œë°œì ì…ì¥ì—ì„œ ì •ë§ í•„ìš”í•œ ì„œë¹„ìŠ¤ ê°™ì•„ìš”, ëŒ€ë‹¨í•©ë‹ˆë‹¤! ğŸ™Œ" \n}'
EMBEDDING_MODEL_NAME = "intfloat/multilingual-e5-small"
CPU_DEVICE = torch.device("cpu")
MAX_NEW_TOKENS = 80
TEMPERATURE = 0.8
TOP_P = 0.8
REPETITION_PENALTY = 1.1
MAX_RETRY = 50


# ----------------------------
# ClovaxModel í´ë˜ìŠ¤
# ----------------------------

class ClovaxModel:
    """
    Clovax ëª¨ë¸ì„ ì‚¬ìš©í•´ ëŒ“ê¸€ ìƒì„±ì„ ë‹´ë‹¹í•˜ëŠ” í´ë˜ìŠ¤
    """
    _is_authenticated = False
    def __init__(self):
        self._authenticate_huggingface()
        self.model_name = MODEL_NAME
        self.device = CPU_DEVICE
        self.tokenizer = None
        self.model = None
        self.pipe = None
        logger.info(f"Device ì„¤ì •: DeviceëŠ” ì˜ë„ì ìœ¼ë¡œ CPUë¡œ ê³ ì •ë©ë‹ˆë‹¤.")
        self.embed_model = None
        
    
    def _authenticate_huggingface(self) -> None:
        """
        .env íŒŒì¼ì—ì„œ HF_AUTH_TOKENì„ ë¡œë“œí•˜ê³  ë¡œê·¸ì¸í•œë‹¤.
        ì¸ì¦ ìµœì í™”ë¥¼ ìœ„í•´ _is_authenticatedê°€ Falseì¼ ê²½ìš°ë§Œ ë¡œê·¸ì¸í•œë‹¤.
        """
        if ClovaxModel._is_authenticated:
            logger.info("Hugging Face ì¸ì¦ ì´ë¯¸ ì™„ë£Œë¨.")
            return  # ì´ë¯¸ ì¸ì¦ë¨ â†’ ê·¸ëƒ¥ ë„˜ì–´ê°

        load_dotenv()
        token = os.getenv("HF_AUTH_TOKEN")
        if not token:
            raise EnvironmentError("HF_AUTH_TOKEN is not set in .env file.")
        login(token=token)

        ClovaxModel._is_authenticated = True  # ì¸ì¦ ì™„ë£Œ ì²˜ë¦¬
        logger.info("Hugging Face ì¸ì¦ ì™„ë£Œ.")


    def load_clovax(self) -> None:
        """
        ëª¨ë¸ê³¼ í† í¬ë‚˜ì´ì €ë¥¼ ë¡œë“œí•˜ì—¬ íŒŒì´í”„ë¼ì¸ì„ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.
        ì´ë¯¸ ì´ˆê¸°í™”ëœ ê²½ìš° ì•„ë¬´ ì‘ì—…ë„ í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
        """
        if self.pipe is None: 
            self.tokenizer = AutoTokenizer.from_pretrained(self.model_name)
            self.model = AutoModelForCausalLM.from_pretrained(self.model_name).to(self.device)
            self.pipe = pipeline(
                "text-generation", 
                model=self.model, 
                tokenizer=self.tokenizer, 
                device=-1, 
                temperature=TEMPERATURE, 
                top_p=TOP_P, 
                do_sample=True,
                repetition_penalty=REPETITION_PENALTY
            )
            self.embed_model = SentenceTransformer(EMBEDDING_MODEL_NAME, device = self.device)
            logger.info("Clovax ëª¨ë¸ ë¡œë“œ ì™„ë£Œ.")
            logger.info("ì„ë² ë”© ê¸°ë°˜ ê²€ì—´ ëª¨ë¸ ë¡œë“œ ì™„ë£Œ.")


    # ëŒ“ê¸€ ìƒì„±
    def validate_generated_comment(self, generated_comment_dict: dict) -> bool:
        """
        ìƒì„±ëœ ëŒ“ê¸€ JSONì´ ìœ íš¨í•œì§€ ê²€ì‚¬.
        í•„ìˆ˜ í•„ë“œ(comment)ê°€ ì—†ê±°ë‚˜ ê°’ì´ ë¹„ì–´ìˆìœ¼ë©´ False
        """
        if "comment" not in generated_comment_dict:
            return False

        comment = generated_comment_dict["comment"]

        if not isinstance(comment, str) or not comment.strip():
            return False
        
        for word in ['ì¶”ê°€', 'í˜ì‹ ì ', 'ì½”ë”©', 'ì½”ë“œ']:
            if word in comment:
                return False
        
        if len(comment.split()) <= 2:
            return False

        return True


    def generate_comment(self, request_data: CommentRequest) -> dict:
        prompt_builder = ClovaxPrompt(request_data)
        prompt: str = prompt_builder.generate_prompt()

        # ğŸ’¡ ê²€ì—´ ê¸°ì¤€ í…ìŠ¤íŠ¸ ìƒì„± (ìš”ì•½, ì„¤ëª…, íƒœê·¸ ë“± ì¡°í•©)
        context_text = " ".join(["ì„œë¹„ìŠ¤ ì´ë¦„ì€",
            request_data.projectSummary.title, "ì´ë‹¤.",
            request_data.projectSummary.introduction,
            request_data.projectSummary.detailedDescription, "ì´ í”„ë¡œì íŠ¸ì˜ í•µì‹¬ì ì¸ íŠ¹ì§•ì€",
            ",".join(request_data.projectSummary.tags), "ì´ë‹¤"
        ])

        for attempt in range(1, MAX_RETRY + 1):
            logger.info(f"ëŒ“ê¸€ ìƒì„± ì‹œë„ {attempt}íšŒ")
            outputs = self.pipe(prompt, max_new_tokens=MAX_NEW_TOKENS)[0]["generated_text"]
            output_text = outputs[len(prompt):].strip()

            try:
                find_comment = re.findall(r'{.*?}', output_text, re.DOTALL)
                generated_comment_str = find_comment[0].strip()
                generated_comment_dict = json.loads(generated_comment_str)
                print(generated_comment_dict)

                # ìœ íš¨ì„± ê²€ì‚¬ ì¶”ê°€
                if self.validate_generated_comment(generated_comment_dict):
                    #logger.info("JSON íŒŒì‹± + ìœ íš¨ì„± ê²€ì‚¬ ì„±ê³µ.")
                    generated_comment = generated_comment_dict.get("comment", "").strip()

                    if self.is_semantically_relevant(generated_comment, context_text):
                        logger.info("JSON íŒŒì‹± + ì˜ë¯¸ í•„í„°ë§ í†µê³¼.")
                        return generated_comment

                    else:
                        logger.info("ì˜ë¯¸ ê²€ì—´ì— ì˜í•´ ëŒ“ê¸€ ì¬ ìƒì„± í•„ìš”.")
                else:
                    raise ValueError("ìƒì„±ëœ JSONì— commentê°€ ì—†ê±°ë‚˜ ë¹„ì–´ ìˆìŒ. í˜•ì‹ì— ë²—ì–´ë‚¨.")

            except (IndexError, json.JSONDecodeError, ValueError) as e:
                logger.warning(f"ëŒ“ê¸€ ìƒì„± ì‹¤íŒ¨ (ì‹œë„ {attempt}íšŒ): {e}")

                if attempt < MAX_RETRY:
                    continue
                else:
                    logger.warning("ìµœëŒ€ ì¬ì‹œë„ ë„ë‹¬ â†’ fallback ì‚¬ìš©.")
                    return json.loads(FALLBACK_COMMENT)


    def is_semantically_relevant(self, comments: str, context: str, threshold: float = 0.85) -> bool:
        """
        ê²€ì—´í•¨ìˆ˜ ìƒì„±. ìƒì„±ëœ ëŒ“ê¸€ì´ í”„ë¡œì íŠ¸ ì •ë³´ì™€ ì˜ë¯¸ì ìœ¼ë¡œ ê´€ë ¨ ìˆëŠ”ì§€ ìœ ì‚¬ë„ë¡œ íŒë‹¨
        """
        comment_emb = self.embed_model.encode("query: " + comments, convert_to_tensor=True, show_progress_bar=False)
        context_emb = self.embed_model.encode("passage: " + context, convert_to_tensor=True, show_progress_bar=False)
        similarity = util.cos_sim(comment_emb, context_emb).item()

        logger.info(f"ì˜ë¯¸ ìœ ì‚¬ë„: {similarity:.4f}")
        return similarity >= threshold


    
# ì‹±ê¸€í„´ ì¸ìŠ¤í„´ìŠ¤ ìƒì„± (ì„œë²„ ì‹œì‘ ì‹œ 1íšŒë§Œ ì‹¤í–‰)
clovax_model_instance = ClovaxModel()
clovax_model_instance.load_clovax()

# ----------------------------
# í…ŒìŠ¤íŠ¸ ì½”ë“œ
# ---------------------------- 

if __name__ == "__main__":
    import time
    import sys
    import os
    from app.fast_api.schemas.comment_schemas import ProjectSummary
    sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), "../../../")))



    dummy_data = CommentRequest(
        commentType="ì¹­ì°¬",
        projectSummary=ProjectSummary(
            title="í’ˆì•—ì´ ì„œë¹„ìŠ¤",
            introduction="ì„œë¡œì˜ í”„ë¡œì íŠ¸ ì›¹í˜ì´ì§€ë¥¼ ë°©ë¬¸í•˜ì—¬ íŠ¸ë˜í”½ì„ ëŠ˜ë ¤ì¤Œ",
            detailedDescription="íŠ¸ë˜í”½ì„ ì›í•˜ëŠ” ë¶€íŠ¸ìº í”„ ìˆ˜ê°•ìƒì„ ìœ„í•´ 22ê°œì˜ íŒ€í”„ë¡œì íŠ¸ë¥¼ í•œë²ˆì— ëª¨ì•„, ì„œë¡œì˜ ì„œë¹„ìŠ¤ë¥¼ ì ‘ê·¼í•˜ê¸° í¸í•œ í”Œë«í¼ì„ êµ¬ì¶•í•¨.",
            deploymentUrl="https://resume.site",
            githubUrl="https://github.com/example",
            tags=["React", "clovax", "FastAPI"],
            teamId=8
        )
    )
    

    start = time.time()
    logger.info("í…ŒìŠ¤íŠ¸ ì‹œì‘.")
    correct = []
    for _ in range(4):
        comment = clovax_model_instance.generate_comment(dummy_data)
        correct.append(comment)
        logger.info("ìƒì„±ëœ ëŒ“ê¸€: %s", comment)
        logger.info("ì‹¤í–‰ ì‹œê°„: %.2fì´ˆ", time.time() - start)

    print(correct)