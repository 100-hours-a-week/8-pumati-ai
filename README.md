# 목차

1. 운세 기능
2. 댓글 기능
3. 뱃지 기능
4. 챗봇 기능

# 기능 별 상세 설명

## 💫 운세 기능

### 1. 개발 목적
 - 가벼운 진입 장벽: 누구나 즐길 수 있는 가벼운 콘텐츠로 가볍게 터치 하고 자연스럽게 서비스를 탐색하도록 돕습니다.
 - 공감대 형성 : 단순한 운세가 아닌, 각 과정별 맞춤 운세를 제공하여 사용자에게 더욱 친근한 느낌으로 다가오도록 합니다.
 - 재방문 유도 : 매일 바뀌는 운세를 통해 사용자의 재방문을 유도할 수 있습니다.
### 2. 모델 선정
 - 
### 3. 주요 이슈
 - 사용자 요구 사항: 최대한 빠른 응답 요구
 - 기술적 요구 사항: 
### 4. 모델 평가 및 결과

  a. 모델 평가
  
  b. 결과
  
  <img src="https://github.com/user-attachments/assets/5bab1198-9dad-4f34-8a2f-10c85de528c9" width="512">

   

## 🗣️ 댓글 기능

### 1. 개발 목적
  - 사용자간 교류 유도: 서로의 프로젝트에 반응하고 관심을 주는 문화를 만듭니다.
  - 댓글 작성의 예시 제공: AI가 각 프로젝트 마다 댓글을 달아주어 각 프로젝트에 대한 댓글 예시를 제공하게 되며, 댓글 작성에 부담을 낮춰줍니다.
  - 피드백 기반의 성장 유도: 각 팀의 아이디어, 기능을 기반으로한 댓글을 통해 개발자가 성장할 수 있는 환경을 제공합니다.
### 2. 모델 선정

- 평가 기준
  
  중요 순위 | 평가 항목 | 설명
  -- | -- | --
  1  | 🧠 성능 | 문장 품질, 감성 표현력, 문맥 이해력
  2  | 🎯 목적 적합성 | - 한글 잘 되는지 + 각 팀의 정보를 보고 알맞은 댓글을 생성할 수 있는지의 여부
  3  | 💸 경량화 | Colab, CPU 환경에서 잘 돌아가는지 / API 비용은 적은지
  4  | 🔥 트렌드 성 | 현재 많이 사용되고, 커뮤니티/지원이 활발한 모델인지
  5  | ⚡ 응답 속도(시간) | 댓글 기능은 최대한 느리게 달릴 수록 좋음.

- 모델 선정 과정
  
  모델명 | 출력 문장 품질 | 실질 조언력 🎯 | 표현 오류 ⚠️ | 응답 속도 ⏱️ | GPU 사용량 (GB) | 댓글 생성 적합성
  -- | -- | -- | -- | -- | -- | --
  **Mistral-7B-Instruct-v0.3** | ⚠️ 반복 있음 | 칭찬 + 기술 언급 그러나 감성 부족 | ✅ 반복 표현 있음 | 10초 | 27.8 | 🟡 중간
  **Gukbap-Mistral-7B** | ⚠️ 반복 있음 | ✅ 진심 어린 칭찬 + 기술 언급 자연스러움 | ✅ 반복 표현 있음 | 10초 | 28.1 | 🟢 매우 적합
  **TinyLlama-1.1B-Chat-v1.0** | ❌ 템플릿 출력 | ⚠️ 새 유형 요청만 반복 출력됨 | ❌ 없음 | 6초 | 7.4 | 🔴 부적합
  **Meta-LLaMA-3-8B-Instruct (GGUF)** | ✅ 매우 좋음 | ✅ 진정성 + 구조적 설명 잘 어울림 | ❌ 없음 | 46초 | 0.0 (CPU 위주) | 🟡 적합 (느림)
  **KORani-v3-13B** | ✅ 좋음 | ✅ 채용담당자 관점 강조, 실용적 접근 | ❌ 없음 | 11초 | 39.3 | 🟡 적합 (VRAM↑)
  **Gemma 3 1B Instruct** | ✅ 매우 좋음 | ✅ 기술 요약 + 문장 정돈 잘됨 | ❌ 없음 | 2초 | 4.9 | 🟢 매우 적합
  **Eximius_Persona_5B-GGUF** | ✅ 감성 표현 우수 | ✅ 사용자 입장 묘사 탁월 | ⚠️ 영어/한글 혼용 있음 | 37초 | 0.0 (CPU 위주) | 🟢 감성 댓글 적합
  **Meta-LLaMA-3-8B-Instruct.Q4_K_M** | ✅ 영어 표현 좋음 | ✅ 개발자 대상 영문 리뷰에 적합 | ❌ 없음 | 46초 | 0.0 | 🟡 영어 리뷰용
  **HyperCLOVAX-SEED-Text-Instruct-1.5B** | ✅ 문장 구성 매우 안정적 | ✅ 기술 요약 + 공손한 표현 훌륭 | ❌ 없음 | 10초 | 8 | 🟢 가장 균형 잡힌 성능

- 최종 모델 (Gemma 3 1B vs HyperCLOVAX-SEED 1.5B) <br>
  -> **Gemma 3 1B Instruct**로 선정됨. <br>
  -> 이유: 개발 과정에서 유사도 모델(sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2")로 입력 데이터와의 유사도를 측정하였으며, 평균적으로 0.4 ~ 0.8를 도출함.
      0.3 ~ 0.7사이였던 HyperCLOVAX보다 **할루시네이션이 적게 일어남**.
      더 긴 입력 프롬프트에 대해서도 댓글처럼 문장을 구성함.

### 3. 주요 이슈

  이슈  |  설명  | 해결 방법 | 결과
  -----|-------|--------|-----
  할루시네이션| 아래와 "환자 데이터"와 같이 프로젝트와 전혀 무관한 기능에 대해 언급하거나, <br>"큰 성과를 거두고 있어요"와 같이 허위 사실을 댓글로 언급함.<br> <img width="600" alt="image" src="https://github.com/user-attachments/assets/2092bfaf-01df-4fb0-a0c4-1ee052a62857" /> | 검열 모델로 임베딩 모델을 추가하여 입력데이터와의 유사도가 0.6 이상인 댓글만 출력함. | 할루시네이션비율이 기존 약 60%에서 20%로 하락함. 
  프롬프트 수정 필요| 사용자 입력으로 받은 데이터 중, 500자 이상의 긴 입력이 있을 시 AI가 이해하지 못함. | TF-IDF 기반 요약 라이브러리를 사용하여 글자수를 줄인 후에 프롬프트에 반영| 500자 이상의 입력에 대해 댓글이 생성됨.
  파라미터 수정 필요| 댓글이 모두 동일한 주제에 대해서 얘기함 | model 로드시, temperature, top_p등의 다양성과 관련된 파라미터를 수정함. | 한번에 생성된 댓글이 모두 다른 주제로 생성됨.
  배포 환경 구축 | Docker 파일 작성, Cloud RUN 오류 해결 등 기타 배포에 필요한 라이브러리 버전 오류를 수정함. | pip show '라이브러리' 명령어로 더 명확한 버전을 requriements.txt에 기재. Cloud RUN 실행 제한 수정| 멈춤 없이 동작하도록 수정.

### 4. 모델 평가 및 결과

  a. 모델 평가

  b. 결과

  
## 🌟 뱃지 기능

### 1. 개발 목적
### 2. 기술 스택
### 3. 주요 이슈
### 4. 모델 평가 및 결과

## 💬 챗봇 기능

### 1. 개발 목적
### 2. 기술 스택
### 3. 주요 이슈
### 4. 모델 평가 및 결과
